# MoonBall Archiver Configuration File

# Preset options for model selection:
#   'speed'     - Uses lighter models optimized for faster performance.
#   'accuracy'  - Uses more advanced models for higher quality embeddings.
#   'default'   - A balanced approach between speed and accuracy.
#   'custom'    - Allows users to manually select models for each category.
#   'fallback'  - Uses a general-purpose fallback model for all file types.
preset: 'default'

# Custom model selection for different file types (only applicable if preset is 'custom')
custom_models:
  Text: distilbert-base-uncased
  Image: CLIP
  Audio: wav2vec2-base
  Video: s3d-k400
  Structured_Data: tabnet
  Code: codebert

# Multi-modal model preference (specifies the model to use if multi-modal is preferred)
# Available options: CLIP, Florence
multi_modal_model: CLIP

# Fallback model to use when a specialized model is not available (only applicable if preset is 'fallback')
# Available options: distilbert-base-uncased, bert-base-uncased, CLIP, ollama, openai
fallback_model: distilbert-base-uncased

# Fallback model settings for service providers (only applicable if fallback_model is 'ollama' or 'openai')
fallback_provider_settings:
  ollama:
    provider: 'ollama'
    model: 'AUTODETECT'  # Name of model to run, or AUTODETECT will use the currently running Ollama model.
    contextLength: 32768  # Context length
    systemMessage: "You are an AI assistant tasked with governing this .mnbl/.ðŸŒ• file. You will answer user queries utilizing the integrated RAG system of embedding and the file index in the header of the .mnbl/.ðŸŒ• file. You will tell the user relevant information pertaining to their queries to the best of your ability leveraging available knowledge of the contents of the .mnbl/.ðŸŒ• file and your own knowledge-base in general as well as any available tools."

  openai:
    provider: 'openai'
    model: 'AUTODETECT'  # Valid options would include all available ChatGPT models through o1 Preview. AUTODETECT with the api base pointed to localhost, a local model could be hosted say via software like â€˜text-generation-webuiâ€™
    systemMessage: "You are an AI assistant tasked with governing this .mnbl/.ðŸŒ• file. You will answer user queries utilizing the integrated RAG system of embedding and the file index in the header of the .mnbl/.ðŸŒ• file. You will tell the user relevant information pertaining to their queries to the best of your ability leveraging available knowledge of the contents of the .mnbl/.ðŸŒ• file and your own knowledge-base in general as well as any available tools."
    contextLength: 32768
    apiKey: ""
    apiBase: "http://localhost:5000/v1"

# Caching option for downloaded models (default is 'True')
# Options: 'true', 'false'
caching: true

# Model download location
model_download_path: "./models"

# Logging level for the application
# Options: DEBUG, INFO, WARNING, ERROR
logging_level: "INFO"

# Number of threads to use for parallel processing
# Options: 'auto' or specify the number of threads
parallel_threads: 'auto'

# Compression level for chunk compression
# Range from 1 (fastest, least compression) to 9 (slowest, maximum compression)
compression_level: 9

# Default chunk size in bytes for file indexing and compression
# The chunk size is adaptive and determined based on the type of data and the compression algorithm used
chunk_size: 5242880  # 5MB default chunk size

# Error handling strategy
# Options: 'continue', 'abort', 'retry'
error_handling: "continue"

# Auto update for models (default is 'true')
# Options: 'true', 'false'
auto_update_models: true

# Compression scheme for MoonBall Archiver
# Options: 'fast', 'balanced', 'max'
scheme: 'balanced'

# Preset configurations:
#   Speed - Lightweight models for faster performance.
#   Accuracy - Higher quality models for best results.
#   Default - Balanced models for general use.

preset_configs:
  speed:
    custom_models:
      Text: distilbert-base-uncased
      Image: resnet18
      Audio: yamnet
      Video: s3d-k400
      Structured_Data: tabnet
      Code: distilbert-base-uncased
    multi_modal: false

  accuracy:
    custom_models:
      Text: bert-base-uncased
      Image: CLIP
      Audio: wav2vec2-base
      Video: i3d
      Structured_Data: ft-transformer
      Code: codebert
    multi_modal: true

  default:
    custom_models:
      Text: distilbert-base-uncased
      Image: CLIP
      Audio: wav2vec2-base
      Video: s3d-k400
      Structured_Data: tabnet
      Code: codebert
    multi_modal: true

# Two-Factor Authentication (2FA) settings
two_factor_authentication:
  enabled: false
  secret_key: "your_secret_key_here"  # Replace with an actual secret key

# Documentation for available custom models and arguments
#
# Preset options:
#   'speed'     - Optimized for faster performance using lightweight models.
#   'accuracy'  - Uses advanced models to provide higher quality embeddings.
#   'default'   - Balanced approach, suitable for most general use cases.
#   'custom'    - Allows manual selection of models for each file type.
#   'fallback'  - Uses a single fallback model for all file types.
#
# Custom model categories:
#   Text: distilbert-base-uncased, bert-base-uncased
#   Image: CLIP, resnet18
#   Audio: wav2vec2-base, yamnet
#   Video: s3d-k400, i3d
#   Structured_Data: tabnet, ft-transformer
#   Code: codebert, gpt-neo
#
# Multi-modal model options (for multi_modal_model setting):
#   CLIP - Default multi-modal model for both text and image.
#   Florence - An alternative multi-modal model.
#
# Fallback model options (for fallback_model setting):
#   distilbert-base-uncased - Lightweight general-purpose text model.
#   bert-base-uncased - Higher accuracy general-purpose text model.
#   CLIP - Multi-modal model suitable for both text and image.
#   ollama - Service provider for fallback with specific settings.
#   openai - Service provider for fallback with specific settings.